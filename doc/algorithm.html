<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<style type="text/css">
body { font-family: HelveticaNeue-Light; color: #111; background-color: #cdcdcd;  margin: 15px;}
h1 { font-size: 30px; color:#1477c6; font-family: HelveticaNeue-Thin; font-weight: 200; }
p { text-align: justify; }
* { font-size: 1em; }
pre { white-space: pre-wrap; font-family: monospace; color: #7f7f7f; background-color: #1a1a1a; }
.Statement { color: #1874cd; font-weight: bold; }
.LineNr { color: #555555; background-color: #0d0d0d; padding-bottom: 1px; }
.Comment { color: #008b00; font-style: italic; }
.Special { color: #009acd; }
</style>
</head>
<body>
<h1>The ProtoScale Algorithm</h1>
<p>
The ProtoScale Algorithm (PSA) is designed to simulate dynamical systems described by differential algebraic equations (DAE) whose structure may be represented as a network. Was designed to simulate structurally dynamic systems potentially unstable systems. The combination of these two properties tends to be a pathological input to most simulation algorithms. Most algorithms can handle one or the other but not both. For example, factorization based algorithms that require complete refactorization in the face of structural changes suffer from the high complexity of factorization. Factorization free methods, such as Krylov subspace approaches suffer from the fact that subspace size (and hence computation complexity) is intrinsically tied to system condition. As systems become more and more stressed, simulation computation becomes more and more expensive. This is unfortunate, as most simulations have the property that the point of highest stress is also the point of highest experimental interest.
</p>

<p>
There are techniques in both of these arenas that attempt to combat these issues [CITATIONS NEEDED]. Fast refactorizers for exact methods and online preconditioners for the Krylov approximation methods have proven to be fruitful in some cases. PSA is an entirely different type of algorithm built from the ground up for these types of simulations specifically. It is a distributed graph based algorithm that provides good scalability. PSA is completely distributed in the sense that each node in the system under simulations structural network need only know about the values of its neighbors. 
</p>

<p>
Enough with the high level rif raf, lets get started with the algorithm. Consider the following system metamodel, the modeling syntax and semantics is foreign please refer to the metamodeling and concrete modeling sections. This meta model describes three nodes and how they interconnect.
</p>

<pre id='vimCodeElement'>
<span id="L1" class="LineNr"> 1 </span><span class="Comment">-- ProtoScale 3 Node MeataModel</span>
<span id="L2" class="LineNr"> 2 </span>
<span id="L3" class="LineNr"> 3 </span><span class="Statement">module</span> Three
<span id="L4" class="LineNr"> 4 </span>
<span id="L5" class="LineNr"> 5 </span><span class="Statement">node</span> Alpha
<span id="L6" class="LineNr"> 6 </span>  info <span class="Special">:=</span> <span class="Special">[</span>a, b, c, v<span class="Special">]</span>
<span id="L7" class="LineNr"> 7 </span>
<span id="L8" class="LineNr"> 8 </span>  beta ij<span class="Special">:</span>Connector j<span class="Special">:</span>Beta <span class="Special">:=</span>
<span id="L9" class="LineNr"> 9 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + c
<span id="L10" class="LineNr">10 </span>
<span id="L11" class="LineNr">11 </span>  gamma ij<span class="Special">:</span>Connector j<span class="Special">:</span>Gamma <span class="Special">:=</span>
<span id="L12" class="LineNr">12 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + x_ij 0.5 (c_j - c)
<span id="L13" class="LineNr">13 </span>
<span id="L14" class="LineNr">14 </span><span class="Statement">node</span> Beta
<span id="L15" class="LineNr">15 </span>  info <span class="Special">:=</span> <span class="Special">[</span>a, b, v<span class="Special">]</span>
<span id="L16" class="LineNr">16 </span>
<span id="L17" class="LineNr">17 </span>  alpha ij<span class="Special">:</span>Connector j<span class="Special">:</span>Alpha <span class="Special">:=</span>
<span id="L18" class="LineNr">18 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + c
<span id="L19" class="LineNr">19 </span>
<span id="L20" class="LineNr">20 </span>  gamma ij<span class="Special">:</span>Connector j<span class="Special">:</span>Gamma <span class="Special">:=</span>
<span id="L21" class="LineNr">21 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + c
<span id="L22" class="LineNr">22 </span>
<span id="L23" class="LineNr">23 </span><span class="Statement">node</span> Gamma
<span id="L24" class="LineNr">24 </span>  info <span class="Special">:=</span> <span class="Special">[</span>a, b, c, d, v<span class="Special">]</span>
<span id="L25" class="LineNr">25 </span>
<span id="L26" class="LineNr">26 </span>  alpha ij<span class="Special">:</span>Connector j<span class="Special">:</span>Alpha <span class="Special">:=</span>
<span id="L27" class="LineNr">27 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + x_ij 0.5 (c_j - c)
<span id="L28" class="LineNr">28 </span>
<span id="L29" class="LineNr">29 </span>  beta ij<span class="Special">:</span>Connector j<span class="Special">:</span>Beta <span class="Special">:=</span>
<span id="L30" class="LineNr">30 </span>    v = x_ij^2 (a - a_i) + (0.5b + 0.5b_j) / x_ij + c
<span id="L31" class="LineNr">31 </span>
<span id="L32" class="LineNr">32 </span>
<span id="L33" class="LineNr">33 </span><span class="Statement">link</span> Connector
<span id="L34" class="LineNr">34 </span>  info <span class="Special">:=</span> <span class="Special">[</span>x<span class="Special">]</span>
<span id="L35" class="LineNr">35 </span>
</pre>

A concrete manifestation of this model is shown in the model code below.
<pre id='vimCodeElement'>
<span id="L1" class="LineNr"> 1 </span><span class="Comment">-- Metamodel three take one</span>
<span id="L2" class="LineNr"> 2 </span>
<span id="L3" class="LineNr"> 3 </span><span class="Statement">import</span> Three
<span id="L4" class="LineNr"> 4 </span>
<span id="L5" class="LineNr"> 5 </span><span class="Statement">create</span> Alpha <span class="Special">{</span>a=1, b=1, c=1, v=1<span class="Special">}</span> a
<span id="L6" class="LineNr"> 6 </span><span class="Statement">create</span> Beta <span class="Special">{</span>a=1, b=1, v=1<span class="Special">}</span> b
<span id="L7" class="LineNr"> 7 </span><span class="Statement">create</span> Gamma <span class="Special">{</span>a=1, b=c, c=1, d=1, v=1<span class="Special">}</span> g
<span id="L8" class="LineNr"> 8 </span>
<span id="L9" class="LineNr"> 9 </span><span class="Statement">create</span> Connector <span class="Special">[</span>x<span class="Special">]</span>
<span id="L10" class="LineNr">10 </span>  c0 <span class="Special">[</span>3<span class="Special">]</span> a b
<span id="L11" class="LineNr">11 </span>  c1 <span class="Special">[</span>4<span class="Special">]</span> b g
<span id="L12" class="LineNr">12 </span>  c2 <span class="Special">[</span>7<span class="Special">]</span> g a
<span id="L13" class="LineNr">13 </span>
</pre>

<p>
A diagrammatic representation of this system is below.
<p>

<center><img src="three_basic.png"/></center>

<p>
The first problem we have, is to find values for <i>a, b, c, d</i> and <i>v</i> such that the interaction relations of the nodes are satisfied.  This does not really count as simulation yet, as we are essentially solving the solution to an instantaneous problem and not a time parametric problem. None the less, the instantaneous solution must be obtained at every time step in the simulation and thus represents a core component of the algorithm.
<p>

<p>
To solve for <i>a, b, c, d</i> and <i>v</i>, we must first settle on a dependent/independent partitioning of our variables. This is where the algorithm begins to tend more toward simulation. The partitioning is triggered by and based upon a change in the value of a nodes variable. The variable that has changed becomes the dependent variable and all the rest be come independents. The problem is now to find values for the independent partition that satisfies the dependent partition. For most interesting nodes (ones with more than 2 variables) this is an overdetermined problem. The goal then for each node within the system is to find an optimal solution to this problem with respect to the global convergence of the rest of the system.
</p>

<p>
The <i>optimum</i> solution to the problem is the one the is equivalent to the global factorization of the system. It is not possible to reach this solution using only a neighborhood's worth of information. A neighborhood of information is the collective information a node has about it's immediate neighbors. The <i>optimal</i> solution is the best attainable approximation of the optimum using only a neighborhood's worth of information. A neighborhood may be parameterized in terms of the number of tiers it contains. A nodes first tier neighbors are the neighbors to which it is directly connected, its second tier neighbors are the neighbors directly connected to its first tier neighbors and so on. Neighborhood size is one of the tuning parameters of the ProtoScale algorithm. Note that in general, as the neighborhood size increases, the problem becomes more determined. Interestingly the 1st and 2nd tier neighborhoods of the 3 node example are identical.
</p>

<p>
The guiding parameter of the optimal solution routine comes from the links. For each link the user must provide a metric indicating the 'distance' the link represents. The optimization routine uses the distances of the links attached to it's node as constraints in determining values for the independent partition. An oversimplified version of how link distances are used is that the degree to which the optimization routine may modify an independent variable from its current value is inversely proportional to a function of the distance by which it is connected. ProtoScale has a default function in place, however, this function may also be supplied by the user as a tuning parameter. It is the design intent of ProtoScale to be highly polymorphic so as to simultaneously provide an implementation and infrastructure for high-performance simulation execution.
</p>

<p>
Once a node has executed the ProtoScale algorithm and has for itself a neighborhood-optimal set of values, it must be propagated and ingested by it's neighbors. We will call this set a step-set. Consider the diagram below.
</p>

<center><img src="three_prop.png"/></center>

<p>
When a node pushes it's step-set out to its neighbors it is received by its neighbors. The receiving neighbor the buffers the relevant portion of the set. In this example alpha pushes the step-set {a,b,c} and gamma the step set {a,b,c,d}, but beta only buffers {a,b} from each. This is indicated by the blue variable blocks. It can be seen that for beta, there are two buffer slots for each variable indicating that it has two neighbors that can influence each variable. When it comes time for beta to resolve it's own view of the neighborhood (represented by the green variable blocks), for each variable it takes a wighted average of the values in it's buffer with its own value. The way in which this average is weighted is also a tunable parameter of the algorithm. After this average is computed the buffer slots are reset to the average.
</p>

<p>
The algorithm is designed to be as asynchronous as possible. When a node observes a change in one of its variables it can either compute a step-set immediately, wait for some amount of time before computing the step-set or wait for some synchronization event to occur. ProtoScale takes the waiting for some amount of time approach. The reason for not performing immediate computation is that in many cases changes are often coupled closely in time with other changes, and waiting for the coupled changes within some time-delta can reduce redundant computation without resorting to serializing synchronization techniques. Put more generally, the local predicates which dictate waiting time should serve to enhance the global convergence of the algorithm without sacrificing scalability. The time spent waiting is another tuning parameter to the algorithm. This is not merely a static number but rather a function which provides parameters that are likely of interest when computing a time step. For example the function provides access to statistics on time-delta coupling per variable. Users can specify the frequency at which this function is run in terms of the current waiting time.

</body>
</html>
